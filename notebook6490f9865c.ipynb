{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10564,
          "sourceType": "datasetVersion",
          "datasetId": 7415
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook6490f9865c",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbui99/Breast-Cancer-Detection-CNN-FastAPI-AWS-Django/blob/main/notebook6490f9865c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "paultimothymooney_breast_histopathology_images_path = kagglehub.dataset_download('paultimothymooney/breast-histopathology-images')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJJW58EZs2bR",
        "outputId": "ace5a4ba-b997-45e7-a860-595cdd580b76"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "0OYLoUXDs2bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nvixp4K5hgc",
        "outputId": "3d03f2bd-9751-4872-f0d6-85173bfb4f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-10T04:57:02.904965Z",
          "iopub.execute_input": "2025-07-10T04:57:02.905494Z",
          "iopub.status.idle": "2025-07-10T04:57:02.910164Z",
          "shell.execute_reply.started": "2025-07-10T04:57:02.905471Z",
          "shell.execute_reply": "2025-07-10T04:57:02.909317Z"
        },
        "id": "doUX1vYNs2ba"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example path to a sample image (adjust based on your walk output)\n",
        "sample_image_path = '/kaggle/input/breast-histopathology-images/10253/0/10253_idx5_x1001_y1001_class0.png'\n",
        "\n",
        "img = cv2.imread(sample_image_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(\"Sample Patch\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-10T04:57:02.917389Z",
          "iopub.execute_input": "2025-07-10T04:57:02.917845Z",
          "iopub.status.idle": "2025-07-10T04:57:03.025185Z",
          "shell.execute_reply.started": "2025-07-10T04:57:02.917827Z",
          "shell.execute_reply": "2025-07-10T04:57:03.024433Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0hbJpmMis2bg",
        "outputId": "4da980a0-355a-43d5-f421-d728b01a0a0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "\n",
        "# Get all image paths\n",
        "all_image_paths = glob.glob('/kaggle/input/breast-histopathology-images/*/*/*.png')\n",
        "\n",
        "\n",
        "# Assign label from filename (1 if _1_ is in name)\n",
        "data = [(path, 1 if '1' in os.path.basename(path) else 0) for path in all_image_paths]\n",
        "\n",
        "# Downsample to a balanced set (e.g., 2000 from each class)\n",
        "class_0 = [d for d in data if d[1] == 0]\n",
        "class_1 = [d for d in data if d[1] == 1]\n",
        "print(f\"Class 0 count: {len(class_0)}\")\n",
        "print(f\"Class 1 count: {len(class_1)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-10T04:57:03.026344Z",
          "iopub.execute_input": "2025-07-10T04:57:03.026599Z",
          "iopub.status.idle": "2025-07-10T04:57:04.563974Z",
          "shell.execute_reply.started": "2025-07-10T04:57:03.02658Z",
          "shell.execute_reply": "2025-07-10T04:57:04.563192Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqxq4_cys2bi",
        "outputId": "2f7095ce-4eca-4d30-971b-369a6b317e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count: 0\n",
            "Class 1 count: 277524\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Created A Balanced Dataset for testing**"
      ],
      "metadata": {
        "id": "uggRiHQ9s2bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "\n",
        "# Get all image paths\n",
        "all_image_paths = glob.glob('/kaggle/input/breast-histopathology-images/*/*/*.png')\n",
        "\n",
        "# Assign label from filename (1 if _1_ is in name)\n",
        "data = [(path, int(os.path.basename(os.path.dirname(path)))) for path in all_image_paths]\n",
        "\n",
        "# Separate by class\n",
        "class_0 = [d for d in data if d[1] == 0]\n",
        "class_1 = [d for d in data if d[1] == 1]\n",
        "\n",
        "print(f\"Class 0 count: {len(class_0)}\")\n",
        "print(f\"Class 1 count: {len(class_1)}\")\n",
        "\n",
        "min_samples = min(len(class_0), len(class_1), 10000)\n",
        "sampled_data = random.sample(class_0, min_samples) + random.sample(class_1, min_samples)\n",
        "random.shuffle(sampled_data)\n",
        "\n",
        "# Split into train and val\n",
        "train_data, val_data = train_test_split(sampled_data, test_size=0.2, stratify=[x[1] for x in sampled_data])\n",
        "\n",
        "#print(f\"sampled_data: {sampled_data}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-10T04:57:04.56468Z",
          "iopub.execute_input": "2025-07-10T04:57:04.564883Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJqMjJ5ms2bk",
        "outputId": "232a2ad5-a599-4d4f-9a0d-e188263bc304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count: 198738\n",
            "Class 1 count: 78786\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare for Training**"
      ],
      "metadata": {
        "id": "kUs-LRwBs2bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for path, label in sampled_data:\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (64, 64))\n",
        "    img = img / 255.0\n",
        "    X.append(img)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVibPd6Rs2bm",
        "outputId": "1edbba75-9979-4dfc-a2ba-e0bc7068cefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.64705882 0.52941176 0.82745098]\n",
            "   [0.59607843 0.43921569 0.72941176]\n",
            "   [0.61176471 0.45098039 0.75686275]\n",
            "   ...\n",
            "   [0.59607843 0.43921569 0.75686275]\n",
            "   [0.56862745 0.39607843 0.70196078]\n",
            "   [0.56470588 0.40784314 0.76078431]]\n",
            "\n",
            "  [[0.6745098  0.54117647 0.81176471]\n",
            "   [0.62352941 0.4745098  0.79215686]\n",
            "   [0.61176471 0.46666667 0.81568627]\n",
            "   ...\n",
            "   [0.61960784 0.48235294 0.83137255]\n",
            "   [0.61176471 0.4627451  0.81960784]\n",
            "   [0.60784314 0.47058824 0.84313725]]\n",
            "\n",
            "  [[0.70588235 0.57647059 0.8       ]\n",
            "   [0.66666667 0.5254902  0.81176471]\n",
            "   [0.63529412 0.49803922 0.83137255]\n",
            "   ...\n",
            "   [0.62745098 0.50196078 0.86666667]\n",
            "   [0.61960784 0.49019608 0.86666667]\n",
            "   [0.61176471 0.48235294 0.87058824]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.69411765 0.58431373 0.78823529]\n",
            "   [0.77254902 0.68627451 0.79607843]\n",
            "   [0.70588235 0.58431373 0.68627451]\n",
            "   ...\n",
            "   [0.58039216 0.45098039 0.85490196]\n",
            "   [0.58823529 0.45882353 0.85098039]\n",
            "   [0.62745098 0.49019608 0.85098039]]\n",
            "\n",
            "  [[0.65098039 0.50196078 0.74509804]\n",
            "   [0.68627451 0.55686275 0.71764706]\n",
            "   [0.65882353 0.5254902  0.6745098 ]\n",
            "   ...\n",
            "   [0.6        0.4745098  0.85882353]\n",
            "   [0.61960784 0.49019608 0.84705882]\n",
            "   [0.66666667 0.53333333 0.84705882]]\n",
            "\n",
            "  [[0.59607843 0.43921569 0.76078431]\n",
            "   [0.63921569 0.49019608 0.7372549 ]\n",
            "   [0.65882353 0.51372549 0.7372549 ]\n",
            "   ...\n",
            "   [0.61568627 0.48235294 0.85882353]\n",
            "   [0.64705882 0.50980392 0.84705882]\n",
            "   [0.69019608 0.57647059 0.84705882]]]\n",
            "\n",
            "\n",
            " [[[0.79215686 0.70588235 0.91372549]\n",
            "   [0.75686275 0.68235294 0.90588235]\n",
            "   [0.7372549  0.6627451  0.90588235]\n",
            "   ...\n",
            "   [0.74901961 0.6627451  0.89019608]\n",
            "   [0.76078431 0.67843137 0.89803922]\n",
            "   [0.76862745 0.69803922 0.90196078]]\n",
            "\n",
            "  [[0.7372549  0.65490196 0.81960784]\n",
            "   [0.76078431 0.68235294 0.87843137]\n",
            "   [0.77254902 0.69803922 0.90196078]\n",
            "   ...\n",
            "   [0.7254902  0.62745098 0.83529412]\n",
            "   [0.75686275 0.67058824 0.8745098 ]\n",
            "   [0.78823529 0.70980392 0.89411765]]\n",
            "\n",
            "  [[0.74117647 0.66666667 0.82745098]\n",
            "   [0.77647059 0.70196078 0.88235294]\n",
            "   [0.78431373 0.70980392 0.90588235]\n",
            "   ...\n",
            "   [0.7372549  0.64313725 0.83921569]\n",
            "   [0.76078431 0.68235294 0.88235294]\n",
            "   [0.77254902 0.69411765 0.90196078]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.81568627 0.7372549  0.90980392]\n",
            "   [0.8        0.72941176 0.90196078]\n",
            "   [0.78431373 0.71372549 0.89803922]\n",
            "   ...\n",
            "   [0.77647059 0.69803922 0.90588235]\n",
            "   [0.78431373 0.70588235 0.90588235]\n",
            "   [0.79607843 0.72156863 0.90588235]]\n",
            "\n",
            "  [[0.8        0.72941176 0.91764706]\n",
            "   [0.78823529 0.71764706 0.90196078]\n",
            "   [0.77647059 0.70196078 0.89411765]\n",
            "   ...\n",
            "   [0.78039216 0.70588235 0.90588235]\n",
            "   [0.78431373 0.71372549 0.90588235]\n",
            "   [0.79607843 0.72941176 0.90980392]]\n",
            "\n",
            "  [[0.77254902 0.71372549 0.92156863]\n",
            "   [0.76470588 0.68627451 0.90980392]\n",
            "   [0.75686275 0.6745098  0.90196078]\n",
            "   ...\n",
            "   [0.78431373 0.71764706 0.89803922]\n",
            "   [0.78823529 0.72156863 0.90588235]\n",
            "   [0.79607843 0.72941176 0.91372549]]]\n",
            "\n",
            "\n",
            " [[[0.94901961 0.9372549  0.94509804]\n",
            "   [0.94117647 0.9372549  0.94901961]\n",
            "   [0.9372549  0.94117647 0.94509804]\n",
            "   ...\n",
            "   [0.9372549  0.94117647 0.94509804]\n",
            "   [0.93333333 0.9372549  0.94117647]\n",
            "   [0.92941176 0.91764706 0.93333333]]\n",
            "\n",
            "  [[0.94509804 0.94117647 0.94901961]\n",
            "   [0.94509804 0.94117647 0.95294118]\n",
            "   [0.94117647 0.9254902  0.94509804]\n",
            "   ...\n",
            "   [0.94901961 0.94509804 0.94901961]\n",
            "   [0.94117647 0.9372549  0.94901961]\n",
            "   [0.93333333 0.92941176 0.94509804]]\n",
            "\n",
            "  [[0.94509804 0.94117647 0.95294118]\n",
            "   [0.94509804 0.94117647 0.94901961]\n",
            "   [0.93333333 0.91764706 0.9372549 ]\n",
            "   ...\n",
            "   [0.94901961 0.94117647 0.94901961]\n",
            "   [0.94509804 0.94117647 0.95294118]\n",
            "   [0.9372549  0.93333333 0.94509804]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.94509804 0.94509804 0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   ...\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]]\n",
            "\n",
            "  [[0.94509804 0.94509804 0.95294118]\n",
            "   [0.94509804 0.94117647 0.95294118]\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   ...\n",
            "   [0.94117647 0.9372549  0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]]\n",
            "\n",
            "  [[0.9372549  0.9372549  0.94901961]\n",
            "   [0.94117647 0.9372549  0.94901961]\n",
            "   [0.94509804 0.9372549  0.94901961]\n",
            "   ...\n",
            "   [0.94117647 0.9372549  0.94901961]\n",
            "   [0.94117647 0.9372549  0.94901961]\n",
            "   [0.94117647 0.9372549  0.94901961]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   ...\n",
            "   [0.94509804 0.94901961 0.94901961]\n",
            "   [0.94509804 0.94901961 0.94509804]\n",
            "   [0.94509804 0.94901961 0.94509804]]\n",
            "\n",
            "  [[0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   ...\n",
            "   [0.94509804 0.94901961 0.94901961]\n",
            "   [0.94509804 0.94901961 0.94901961]\n",
            "   [0.94509804 0.94509804 0.94901961]]\n",
            "\n",
            "  [[0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   ...\n",
            "   [0.94509804 0.94901961 0.94901961]\n",
            "   [0.94509804 0.94901961 0.94901961]\n",
            "   [0.94509804 0.94509804 0.94901961]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.93333333 0.93333333 0.94509804]\n",
            "   [0.9372549  0.9372549  0.94117647]\n",
            "   [0.94117647 0.94117647 0.94117647]\n",
            "   ...\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]]\n",
            "\n",
            "  [[0.9372549  0.94117647 0.94117647]\n",
            "   [0.9372549  0.94117647 0.94509804]\n",
            "   [0.94117647 0.9372549  0.94117647]\n",
            "   ...\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]]\n",
            "\n",
            "  [[0.94117647 0.9372549  0.94509804]\n",
            "   [0.94509804 0.93333333 0.94509804]\n",
            "   [0.94117647 0.94117647 0.94509804]\n",
            "   ...\n",
            "   [0.94509804 0.94117647 0.94509804]\n",
            "   [0.94509804 0.94117647 0.94509804]\n",
            "   [0.94509804 0.94509804 0.94509804]]]\n",
            "\n",
            "\n",
            " [[[0.87058824 0.77254902 0.83921569]\n",
            "   [0.82745098 0.71764706 0.83921569]\n",
            "   [0.81176471 0.69803922 0.81176471]\n",
            "   ...\n",
            "   [0.9372549  0.92941176 0.9372549 ]\n",
            "   [0.83137255 0.76470588 0.82745098]\n",
            "   [0.61176471 0.44705882 0.60392157]]\n",
            "\n",
            "  [[0.61568627 0.41176471 0.63921569]\n",
            "   [0.59607843 0.4        0.59607843]\n",
            "   [0.58823529 0.40392157 0.58431373]\n",
            "   ...\n",
            "   [0.75686275 0.63529412 0.73333333]\n",
            "   [0.67843137 0.52941176 0.66666667]\n",
            "   [0.58039216 0.41568627 0.58431373]]\n",
            "\n",
            "  [[0.46666667 0.23137255 0.48235294]\n",
            "   [0.49019608 0.25490196 0.48235294]\n",
            "   [0.51372549 0.28627451 0.52156863]\n",
            "   ...\n",
            "   [0.63921569 0.44705882 0.62745098]\n",
            "   [0.60392157 0.39607843 0.63137255]\n",
            "   [0.56470588 0.37254902 0.61960784]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.63921569 0.45490196 0.64313725]\n",
            "   [0.59607843 0.38431373 0.61176471]\n",
            "   [0.58039216 0.35294118 0.60784314]\n",
            "   ...\n",
            "   [0.79607843 0.70588235 0.81960784]\n",
            "   [0.92941176 0.91764706 0.9372549 ]\n",
            "   [0.94509804 0.9254902  0.94117647]]\n",
            "\n",
            "  [[0.65098039 0.45098039 0.66666667]\n",
            "   [0.56078431 0.3372549  0.56078431]\n",
            "   [0.55294118 0.3254902  0.56862745]\n",
            "   ...\n",
            "   [0.74901961 0.64313725 0.76470588]\n",
            "   [0.90588235 0.87843137 0.91372549]\n",
            "   [0.92941176 0.90196078 0.9254902 ]]\n",
            "\n",
            "  [[0.70588235 0.52156863 0.73333333]\n",
            "   [0.60392157 0.38431373 0.6       ]\n",
            "   [0.54901961 0.31764706 0.54117647]\n",
            "   ...\n",
            "   [0.67058824 0.50588235 0.65098039]\n",
            "   [0.83529412 0.75686275 0.83529412]\n",
            "   [0.88235294 0.83529412 0.89803922]]]\n",
            "\n",
            "\n",
            " [[[0.52156863 0.34901961 0.6745098 ]\n",
            "   [0.66666667 0.53333333 0.76078431]\n",
            "   [0.67058824 0.54117647 0.76862745]\n",
            "   ...\n",
            "   [0.8627451  0.81176471 0.90980392]\n",
            "   [0.86666667 0.81960784 0.90980392]\n",
            "   [0.93333333 0.92941176 0.94509804]]\n",
            "\n",
            "  [[0.52941176 0.35294118 0.7254902 ]\n",
            "   [0.54509804 0.38823529 0.70588235]\n",
            "   [0.65098039 0.5254902  0.74901961]\n",
            "   ...\n",
            "   [0.79607843 0.71764706 0.85098039]\n",
            "   [0.74509804 0.63921569 0.81568627]\n",
            "   [0.85490196 0.79607843 0.90588235]]\n",
            "\n",
            "  [[0.62352941 0.47058824 0.78039216]\n",
            "   [0.5372549  0.36862745 0.71764706]\n",
            "   [0.61176471 0.47058824 0.74509804]\n",
            "   ...\n",
            "   [0.75686275 0.6627451  0.79607843]\n",
            "   [0.64705882 0.49411765 0.72156863]\n",
            "   [0.69411765 0.57647059 0.79607843]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.61176471 0.4627451  0.81176471]\n",
            "   [0.61960784 0.46666667 0.81960784]\n",
            "   [0.61176471 0.45882353 0.79215686]\n",
            "   ...\n",
            "   [0.64705882 0.52156863 0.79607843]\n",
            "   [0.64313725 0.52941176 0.76862745]\n",
            "   [0.68235294 0.57647059 0.72941176]]\n",
            "\n",
            "  [[0.61568627 0.46666667 0.80392157]\n",
            "   [0.63137255 0.48627451 0.81960784]\n",
            "   [0.63529412 0.49411765 0.81176471]\n",
            "   ...\n",
            "   [0.60784314 0.47058824 0.72941176]\n",
            "   [0.60784314 0.49019608 0.72156863]\n",
            "   [0.68235294 0.58823529 0.70588235]]\n",
            "\n",
            "  [[0.62352941 0.4745098  0.8       ]\n",
            "   [0.64313725 0.50588235 0.81568627]\n",
            "   [0.65882353 0.52156863 0.82745098]\n",
            "   ...\n",
            "   [0.6627451  0.53333333 0.73333333]\n",
            "   [0.74117647 0.63921569 0.8       ]\n",
            "   [0.81176471 0.74117647 0.83137255]]]]\n",
            "[1 0 0 ... 0 1 0]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Dataset Class**"
      ],
      "metadata": {
        "id": "A9CPAVFRs2bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HistopathologyDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.data[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "\n",
        "print(f\"Define success\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCsZQpZ_s2bn",
        "outputId": "1bf00d5d-f112-4c3d-acb0-e6583e5718e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Define success\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = HistopathologyDataset(train_data, train_transform)\n",
        "val_dataset = HistopathologyDataset(val_data, val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "print(f\"Train dataset: {train_dataset}\")\n",
        "print(f\"Val dataset: {val_dataset}\")\n",
        "\n",
        "print(f\"Train loader: {train_loader}\")\n",
        "print(f\"Val loader: {val_loader}\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69RffF1Ns2bo",
        "outputId": "44fe095b-3686-40f8-ddeb-539e020b3693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: <__main__.HistopathologyDataset object at 0x78c33cd3b390>\n",
            "Val dataset: <__main__.HistopathologyDataset object at 0x78c33cd3b750>\n",
            "Train loader: <torch.utils.data.dataloader.DataLoader object at 0x78c220377e50>\n",
            "Val loader: <torch.utils.data.dataloader.DataLoader object at 0x78c269701290>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a CNN Model**"
      ],
      "metadata": {
        "id": "OQ4VqI9Zs2bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 64x64 → 64x64\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # → 32x32\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # → 32x32\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # → 16x16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # → 16x16\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # → 8x8\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 8 * 8, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)  # raw logit\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(-1)  # Ensure shape [batch_size]\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "qQ3HMbY1s2bp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train model**"
      ],
      "metadata": {
        "id": "Qu7DQokPs2bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "\n",
        "EPOCHS = 100\n",
        "PATIENCE = 10  # Stop training if no improvement after this many epochs\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "early_stop = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# --- Choose optimizer ---\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.003)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # ---------------- Validation ----------------\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > 0.5).float().cpu().numpy()\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"Validation metrics for Epoch {epoch+1}:\\n{classification_report(y_true, y_pred, digits=4)}\")\n",
        "\n",
        "    # ---------------- Early Stopping ----------------\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "            early_stop = True\n",
        "            break\n",
        "\n",
        "if early_stop:\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3FaBlEDs2bq",
        "outputId": "4ec26541-1180-44d2-9b43-d999803ce21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6415, Train Accuracy: 0.7739\n",
            "Validation Loss: 0.5255\n",
            "Validation metrics for Epoch 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8388    0.6140    0.7090      2000\n",
            "         1.0     0.6956    0.8820    0.7778      2000\n",
            "\n",
            "    accuracy                         0.7480      4000\n",
            "   macro avg     0.7672    0.7480    0.7434      4000\n",
            "weighted avg     0.7672    0.7480    0.7434      4000\n",
            "\n",
            "Epoch 2, Loss: 0.5072, Train Accuracy: 0.7812\n",
            "Validation Loss: 0.4432\n",
            "Validation metrics for Epoch 2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8804    0.6700    0.7609      2000\n",
            "         1.0     0.7337    0.9090    0.8120      2000\n",
            "\n",
            "    accuracy                         0.7895      4000\n",
            "   macro avg     0.8070    0.7895    0.7865      4000\n",
            "weighted avg     0.8070    0.7895    0.7865      4000\n",
            "\n",
            "Epoch 3, Loss: 0.4964, Train Accuracy: 0.7809\n",
            "Validation Loss: 0.4935\n",
            "Validation metrics for Epoch 3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7187    0.8815    0.7918      2000\n",
            "         1.0     0.8468    0.6550    0.7387      2000\n",
            "\n",
            "    accuracy                         0.7682      4000\n",
            "   macro avg     0.7828    0.7682    0.7652      4000\n",
            "weighted avg     0.7828    0.7682    0.7652      4000\n",
            "\n",
            "Epoch 4, Loss: 0.4877, Train Accuracy: 0.7895\n",
            "Validation Loss: 0.6593\n",
            "Validation metrics for Epoch 4:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.6950    0.9125    0.7890      2000\n",
            "         1.0     0.8726    0.5995    0.7107      2000\n",
            "\n",
            "    accuracy                         0.7560      4000\n",
            "   macro avg     0.7838    0.7560    0.7499      4000\n",
            "weighted avg     0.7838    0.7560    0.7499      4000\n",
            "\n",
            "Epoch 5, Loss: 0.4765, Train Accuracy: 0.7928\n",
            "Validation Loss: 0.4468\n",
            "Validation metrics for Epoch 5:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8291    0.7615    0.7938      2000\n",
            "         1.0     0.7795    0.8430    0.8100      2000\n",
            "\n",
            "    accuracy                         0.8023      4000\n",
            "   macro avg     0.8043    0.8022    0.8019      4000\n",
            "weighted avg     0.8043    0.8023    0.8019      4000\n",
            "\n",
            "Epoch 6, Loss: 0.4762, Train Accuracy: 0.7960\n",
            "Validation Loss: 0.3998\n",
            "Validation metrics for Epoch 6:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8343    0.8280    0.8311      2000\n",
            "         1.0     0.8293    0.8355    0.8324      2000\n",
            "\n",
            "    accuracy                         0.8317      4000\n",
            "   macro avg     0.8318    0.8317    0.8317      4000\n",
            "weighted avg     0.8318    0.8317    0.8317      4000\n",
            "\n",
            "Epoch 7, Loss: 0.4654, Train Accuracy: 0.7997\n",
            "Validation Loss: 0.4528\n",
            "Validation metrics for Epoch 7:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9354    0.5860    0.7206      2000\n",
            "         1.0     0.6986    0.9595    0.8085      2000\n",
            "\n",
            "    accuracy                         0.7728      4000\n",
            "   macro avg     0.8170    0.7728    0.7645      4000\n",
            "weighted avg     0.8170    0.7728    0.7645      4000\n",
            "\n",
            "Epoch 8, Loss: 0.4524, Train Accuracy: 0.8051\n",
            "Validation Loss: 0.4647\n",
            "Validation metrics for Epoch 8:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9290    0.5890    0.7209      2000\n",
            "         1.0     0.6991    0.9550    0.8073      2000\n",
            "\n",
            "    accuracy                         0.7720      4000\n",
            "   macro avg     0.8141    0.7720    0.7641      4000\n",
            "weighted avg     0.8141    0.7720    0.7641      4000\n",
            "\n",
            "Epoch 9, Loss: 0.4407, Train Accuracy: 0.8106\n",
            "Validation Loss: 0.5178\n",
            "Validation metrics for Epoch 9:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7561    0.8835    0.8148      2000\n",
            "         1.0     0.8599    0.7150    0.7808      2000\n",
            "\n",
            "    accuracy                         0.7993      4000\n",
            "   macro avg     0.8080    0.7993    0.7978      4000\n",
            "weighted avg     0.8080    0.7993    0.7978      4000\n",
            "\n",
            "Epoch 10, Loss: 0.4349, Train Accuracy: 0.8161\n",
            "Validation Loss: 0.4094\n",
            "Validation metrics for Epoch 10:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8033    0.8575    0.8295      2000\n",
            "         1.0     0.8472    0.7900    0.8176      2000\n",
            "\n",
            "    accuracy                         0.8237      4000\n",
            "   macro avg     0.8252    0.8237    0.8235      4000\n",
            "weighted avg     0.8252    0.8237    0.8235      4000\n",
            "\n",
            "Epoch 11, Loss: 0.4149, Train Accuracy: 0.8279\n",
            "Validation Loss: 0.3691\n",
            "Validation metrics for Epoch 11:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8597    0.8090    0.8336      2000\n",
            "         1.0     0.8196    0.8680    0.8431      2000\n",
            "\n",
            "    accuracy                         0.8385      4000\n",
            "   macro avg     0.8397    0.8385    0.8384      4000\n",
            "weighted avg     0.8397    0.8385    0.8384      4000\n",
            "\n",
            "Epoch 12, Loss: 0.4029, Train Accuracy: 0.8297\n",
            "Validation Loss: 0.3744\n",
            "Validation metrics for Epoch 12:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8576    0.8250    0.8410      2000\n",
            "         1.0     0.8314    0.8630    0.8469      2000\n",
            "\n",
            "    accuracy                         0.8440      4000\n",
            "   macro avg     0.8445    0.8440    0.8439      4000\n",
            "weighted avg     0.8445    0.8440    0.8439      4000\n",
            "\n",
            "Epoch 13, Loss: 0.3993, Train Accuracy: 0.8363\n",
            "Validation Loss: 0.3685\n",
            "Validation metrics for Epoch 13:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8403    0.8525    0.8464      2000\n",
            "         1.0     0.8503    0.8380    0.8441      2000\n",
            "\n",
            "    accuracy                         0.8452      4000\n",
            "   macro avg     0.8453    0.8453    0.8452      4000\n",
            "weighted avg     0.8453    0.8452    0.8452      4000\n",
            "\n",
            "Epoch 14, Loss: 0.3915, Train Accuracy: 0.8358\n",
            "Validation Loss: 1.2893\n",
            "Validation metrics for Epoch 14:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.6137    0.9665    0.7507      2000\n",
            "         1.0     0.9212    0.3915    0.5495      2000\n",
            "\n",
            "    accuracy                         0.6790      4000\n",
            "   macro avg     0.7674    0.6790    0.6501      4000\n",
            "weighted avg     0.7674    0.6790    0.6501      4000\n",
            "\n",
            "Epoch 15, Loss: 0.3901, Train Accuracy: 0.8389\n",
            "Validation Loss: 0.4066\n",
            "Validation metrics for Epoch 15:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7789    0.9070    0.8381      2000\n",
            "         1.0     0.8887    0.7425    0.8090      2000\n",
            "\n",
            "    accuracy                         0.8247      4000\n",
            "   macro avg     0.8338    0.8248    0.8236      4000\n",
            "weighted avg     0.8338    0.8247    0.8236      4000\n",
            "\n",
            "Epoch 16, Loss: 0.3846, Train Accuracy: 0.8365\n",
            "Validation Loss: 0.3445\n",
            "Validation metrics for Epoch 16:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8822    0.8200    0.8500      2000\n",
            "         1.0     0.8319    0.8905    0.8602      2000\n",
            "\n",
            "    accuracy                         0.8552      4000\n",
            "   macro avg     0.8570    0.8552    0.8551      4000\n",
            "weighted avg     0.8570    0.8552    0.8551      4000\n",
            "\n",
            "Epoch 17, Loss: 0.3832, Train Accuracy: 0.8441\n",
            "Validation Loss: 0.3381\n",
            "Validation metrics for Epoch 17:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8558    0.8695    0.8626      2000\n",
            "         1.0     0.8674    0.8535    0.8604      2000\n",
            "\n",
            "    accuracy                         0.8615      4000\n",
            "   macro avg     0.8616    0.8615    0.8615      4000\n",
            "weighted avg     0.8616    0.8615    0.8615      4000\n",
            "\n",
            "Epoch 18, Loss: 0.3766, Train Accuracy: 0.8445\n",
            "Validation Loss: 0.3433\n",
            "Validation metrics for Epoch 18:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8572    0.8615    0.8594      2000\n",
            "         1.0     0.8608    0.8565    0.8586      2000\n",
            "\n",
            "    accuracy                         0.8590      4000\n",
            "   macro avg     0.8590    0.8590    0.8590      4000\n",
            "weighted avg     0.8590    0.8590    0.8590      4000\n",
            "\n",
            "Epoch 19, Loss: 0.3810, Train Accuracy: 0.8413\n",
            "Validation Loss: 0.3882\n",
            "Validation metrics for Epoch 19:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8594    0.8250    0.8418      2000\n",
            "         1.0     0.8317    0.8650    0.8480      2000\n",
            "\n",
            "    accuracy                         0.8450      4000\n",
            "   macro avg     0.8456    0.8450    0.8449      4000\n",
            "weighted avg     0.8456    0.8450    0.8449      4000\n",
            "\n",
            "Epoch 20, Loss: 0.3727, Train Accuracy: 0.8456\n",
            "Validation Loss: 0.3639\n",
            "Validation metrics for Epoch 20:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8187    0.8985    0.8567      2000\n",
            "         1.0     0.8875    0.8010    0.8420      2000\n",
            "\n",
            "    accuracy                         0.8498      4000\n",
            "   macro avg     0.8531    0.8498    0.8494      4000\n",
            "weighted avg     0.8531    0.8498    0.8494      4000\n",
            "\n",
            "Epoch 21, Loss: 0.3663, Train Accuracy: 0.8492\n",
            "Validation Loss: 0.3594\n",
            "Validation metrics for Epoch 21:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8270    0.8865    0.8557      2000\n",
            "         1.0     0.8777    0.8145    0.8449      2000\n",
            "\n",
            "    accuracy                         0.8505      4000\n",
            "   macro avg     0.8523    0.8505    0.8503      4000\n",
            "weighted avg     0.8523    0.8505    0.8503      4000\n",
            "\n",
            "Epoch 22, Loss: 0.3573, Train Accuracy: 0.8551\n",
            "Validation Loss: 0.3874\n",
            "Validation metrics for Epoch 22:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8128    0.9010    0.8546      2000\n",
            "         1.0     0.8890    0.7925    0.8380      2000\n",
            "\n",
            "    accuracy                         0.8468      4000\n",
            "   macro avg     0.8509    0.8468    0.8463      4000\n",
            "weighted avg     0.8509    0.8468    0.8463      4000\n",
            "\n",
            "Epoch 23, Loss: 0.3537, Train Accuracy: 0.8564\n",
            "Validation Loss: 0.3570\n",
            "Validation metrics for Epoch 23:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8140    0.9100    0.8593      2000\n",
            "         1.0     0.8980    0.7920    0.8417      2000\n",
            "\n",
            "    accuracy                         0.8510      4000\n",
            "   macro avg     0.8560    0.8510    0.8505      4000\n",
            "weighted avg     0.8560    0.8510    0.8505      4000\n",
            "\n",
            "Epoch 24, Loss: 0.3495, Train Accuracy: 0.8560\n",
            "Validation Loss: 0.3926\n",
            "Validation metrics for Epoch 24:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7932    0.9185    0.8513      2000\n",
            "         1.0     0.9032    0.7605    0.8257      2000\n",
            "\n",
            "    accuracy                         0.8395      4000\n",
            "   macro avg     0.8482    0.8395    0.8385      4000\n",
            "weighted avg     0.8482    0.8395    0.8385      4000\n",
            "\n",
            "Epoch 25, Loss: 0.3472, Train Accuracy: 0.8562\n",
            "Validation Loss: 0.3276\n",
            "Validation metrics for Epoch 25:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8897    0.8345    0.8612      2000\n",
            "         1.0     0.8442    0.8965    0.8695      2000\n",
            "\n",
            "    accuracy                         0.8655      4000\n",
            "   macro avg     0.8669    0.8655    0.8654      4000\n",
            "weighted avg     0.8669    0.8655    0.8654      4000\n",
            "\n",
            "Epoch 26, Loss: 0.3503, Train Accuracy: 0.8549\n",
            "Validation Loss: 0.3258\n",
            "Validation metrics for Epoch 26:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8998    0.8170    0.8564      2000\n",
            "         1.0     0.8324    0.9090    0.8690      2000\n",
            "\n",
            "    accuracy                         0.8630      4000\n",
            "   macro avg     0.8661    0.8630    0.8627      4000\n",
            "weighted avg     0.8661    0.8630    0.8627      4000\n",
            "\n",
            "Epoch 27, Loss: 0.3473, Train Accuracy: 0.8575\n",
            "Validation Loss: 0.3161\n",
            "Validation metrics for Epoch 27:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8701    0.8710    0.8706      2000\n",
            "         1.0     0.8709    0.8700    0.8704      2000\n",
            "\n",
            "    accuracy                         0.8705      4000\n",
            "   macro avg     0.8705    0.8705    0.8705      4000\n",
            "weighted avg     0.8705    0.8705    0.8705      4000\n",
            "\n",
            "Epoch 28, Loss: 0.3438, Train Accuracy: 0.8581\n",
            "Validation Loss: 0.3188\n",
            "Validation metrics for Epoch 28:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8695    0.8660    0.8677      2000\n",
            "         1.0     0.8665    0.8700    0.8683      2000\n",
            "\n",
            "    accuracy                         0.8680      4000\n",
            "   macro avg     0.8680    0.8680    0.8680      4000\n",
            "weighted avg     0.8680    0.8680    0.8680      4000\n",
            "\n",
            "Epoch 29, Loss: 0.3368, Train Accuracy: 0.8631\n",
            "Validation Loss: 0.3785\n",
            "Validation metrics for Epoch 29:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8083    0.9000    0.8517      2000\n",
            "         1.0     0.8872    0.7865    0.8338      2000\n",
            "\n",
            "    accuracy                         0.8433      4000\n",
            "   macro avg     0.8477    0.8433    0.8427      4000\n",
            "weighted avg     0.8477    0.8433    0.8427      4000\n",
            "\n",
            "Epoch 30, Loss: 0.3391, Train Accuracy: 0.8598\n",
            "Validation Loss: 0.3261\n",
            "Validation metrics for Epoch 30:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8650    0.8745    0.8697      2000\n",
            "         1.0     0.8731    0.8635    0.8683      2000\n",
            "\n",
            "    accuracy                         0.8690      4000\n",
            "   macro avg     0.8690    0.8690    0.8690      4000\n",
            "weighted avg     0.8690    0.8690    0.8690      4000\n",
            "\n",
            "Epoch 31, Loss: 0.3276, Train Accuracy: 0.8649\n",
            "Validation Loss: 0.3293\n",
            "Validation metrics for Epoch 31:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8656    0.8725    0.8690      2000\n",
            "         1.0     0.8715    0.8645    0.8680      2000\n",
            "\n",
            "    accuracy                         0.8685      4000\n",
            "   macro avg     0.8685    0.8685    0.8685      4000\n",
            "weighted avg     0.8685    0.8685    0.8685      4000\n",
            "\n",
            "Epoch 32, Loss: 0.3275, Train Accuracy: 0.8659\n",
            "Validation Loss: 0.3208\n",
            "Validation metrics for Epoch 32:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8806    0.8625    0.8714      2000\n",
            "         1.0     0.8653    0.8830    0.8740      2000\n",
            "\n",
            "    accuracy                         0.8728      4000\n",
            "   macro avg     0.8729    0.8728    0.8727      4000\n",
            "weighted avg     0.8729    0.8728    0.8727      4000\n",
            "\n",
            "Epoch 33, Loss: 0.3283, Train Accuracy: 0.8643\n",
            "Validation Loss: 0.3191\n",
            "Validation metrics for Epoch 33:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8649    0.8870    0.8758      2000\n",
            "         1.0     0.8840    0.8615    0.8726      2000\n",
            "\n",
            "    accuracy                         0.8742      4000\n",
            "   macro avg     0.8745    0.8742    0.8742      4000\n",
            "weighted avg     0.8745    0.8742    0.8742      4000\n",
            "\n",
            "Epoch 34, Loss: 0.3219, Train Accuracy: 0.8671\n",
            "Validation Loss: 0.3379\n",
            "Validation metrics for Epoch 34:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8365    0.9055    0.8696      2000\n",
            "         1.0     0.8970    0.8230    0.8584      2000\n",
            "\n",
            "    accuracy                         0.8642      4000\n",
            "   macro avg     0.8667    0.8642    0.8640      4000\n",
            "weighted avg     0.8667    0.8642    0.8640      4000\n",
            "\n",
            "Epoch 35, Loss: 0.3205, Train Accuracy: 0.8672\n",
            "Validation Loss: 0.3166\n",
            "Validation metrics for Epoch 35:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8763    0.8575    0.8668      2000\n",
            "         1.0     0.8605    0.8790    0.8697      2000\n",
            "\n",
            "    accuracy                         0.8682      4000\n",
            "   macro avg     0.8684    0.8682    0.8682      4000\n",
            "weighted avg     0.8684    0.8682    0.8682      4000\n",
            "\n",
            "Epoch 36, Loss: 0.3197, Train Accuracy: 0.8669\n",
            "Validation Loss: 0.3148\n",
            "Validation metrics for Epoch 36:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8833    0.8475    0.8650      2000\n",
            "         1.0     0.8534    0.8880    0.8704      2000\n",
            "\n",
            "    accuracy                         0.8678      4000\n",
            "   macro avg     0.8684    0.8678    0.8677      4000\n",
            "weighted avg     0.8684    0.8678    0.8677      4000\n",
            "\n",
            "Epoch 37, Loss: 0.3166, Train Accuracy: 0.8676\n",
            "Validation Loss: 0.3141\n",
            "Validation metrics for Epoch 37:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8652    0.8860    0.8755      2000\n",
            "         1.0     0.8832    0.8620    0.8725      2000\n",
            "\n",
            "    accuracy                         0.8740      4000\n",
            "   macro avg     0.8742    0.8740    0.8740      4000\n",
            "weighted avg     0.8742    0.8740    0.8740      4000\n",
            "\n",
            "Epoch 38, Loss: 0.3141, Train Accuracy: 0.8672\n",
            "Validation Loss: 0.3147\n",
            "Validation metrics for Epoch 38:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8863    0.8420    0.8636      2000\n",
            "         1.0     0.8495    0.8920    0.8702      2000\n",
            "\n",
            "    accuracy                         0.8670      4000\n",
            "   macro avg     0.8679    0.8670    0.8669      4000\n",
            "weighted avg     0.8679    0.8670    0.8669      4000\n",
            "\n",
            "Epoch 39, Loss: 0.3152, Train Accuracy: 0.8702\n",
            "Validation Loss: 0.3179\n",
            "Validation metrics for Epoch 39:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8730    0.8665    0.8698      2000\n",
            "         1.0     0.8675    0.8740    0.8707      2000\n",
            "\n",
            "    accuracy                         0.8702      4000\n",
            "   macro avg     0.8703    0.8702    0.8702      4000\n",
            "weighted avg     0.8703    0.8702    0.8702      4000\n",
            "\n",
            "Epoch 40, Loss: 0.3148, Train Accuracy: 0.8694\n",
            "Validation Loss: 0.3247\n",
            "Validation metrics for Epoch 40:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8800    0.8510    0.8653      2000\n",
            "         1.0     0.8558    0.8840    0.8697      2000\n",
            "\n",
            "    accuracy                         0.8675      4000\n",
            "   macro avg     0.8679    0.8675    0.8675      4000\n",
            "weighted avg     0.8679    0.8675    0.8675      4000\n",
            "\n",
            "Epoch 41, Loss: 0.3062, Train Accuracy: 0.8728\n",
            "Validation Loss: 0.3194\n",
            "Validation metrics for Epoch 41:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8603    0.8805    0.8703      2000\n",
            "         1.0     0.8776    0.8570    0.8672      2000\n",
            "\n",
            "    accuracy                         0.8688      4000\n",
            "   macro avg     0.8690    0.8687    0.8687      4000\n",
            "weighted avg     0.8690    0.8688    0.8687      4000\n",
            "\n",
            "Epoch 42, Loss: 0.3044, Train Accuracy: 0.8728\n",
            "Validation Loss: 0.3200\n",
            "Validation metrics for Epoch 42:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8711    0.8755    0.8733      2000\n",
            "         1.0     0.8749    0.8705    0.8727      2000\n",
            "\n",
            "    accuracy                         0.8730      4000\n",
            "   macro avg     0.8730    0.8730    0.8730      4000\n",
            "weighted avg     0.8730    0.8730    0.8730      4000\n",
            "\n",
            "Epoch 43, Loss: 0.3041, Train Accuracy: 0.8747\n",
            "Validation Loss: 0.3158\n",
            "Validation metrics for Epoch 43:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8732    0.8675    0.8703      2000\n",
            "         1.0     0.8684    0.8740    0.8712      2000\n",
            "\n",
            "    accuracy                         0.8708      4000\n",
            "   macro avg     0.8708    0.8708    0.8707      4000\n",
            "weighted avg     0.8708    0.8708    0.8707      4000\n",
            "\n",
            "Epoch 44, Loss: 0.3033, Train Accuracy: 0.8735\n",
            "Validation Loss: 0.3279\n",
            "Validation metrics for Epoch 44:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8481    0.8905    0.8688      2000\n",
            "         1.0     0.8847    0.8405    0.8621      2000\n",
            "\n",
            "    accuracy                         0.8655      4000\n",
            "   macro avg     0.8664    0.8655    0.8654      4000\n",
            "weighted avg     0.8664    0.8655    0.8654      4000\n",
            "\n",
            "Epoch 45, Loss: 0.3003, Train Accuracy: 0.8739\n",
            "Validation Loss: 0.3170\n",
            "Validation metrics for Epoch 45:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8885    0.8490    0.8683      2000\n",
            "         1.0     0.8554    0.8935    0.8741      2000\n",
            "\n",
            "    accuracy                         0.8712      4000\n",
            "   macro avg     0.8720    0.8712    0.8712      4000\n",
            "weighted avg     0.8720    0.8712    0.8712      4000\n",
            "\n",
            "Epoch 46, Loss: 0.3020, Train Accuracy: 0.8756\n",
            "Validation Loss: 0.3146\n",
            "Validation metrics for Epoch 46:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8650    0.8840    0.8744      2000\n",
            "         1.0     0.8814    0.8620    0.8716      2000\n",
            "\n",
            "    accuracy                         0.8730      4000\n",
            "   macro avg     0.8732    0.8730    0.8730      4000\n",
            "weighted avg     0.8732    0.8730    0.8730      4000\n",
            "\n",
            "Epoch 47, Loss: 0.2995, Train Accuracy: 0.8758\n",
            "Validation Loss: 0.3181\n",
            "Validation metrics for Epoch 47:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8879    0.8515    0.8693      2000\n",
            "         1.0     0.8573    0.8925    0.8746      2000\n",
            "\n",
            "    accuracy                         0.8720      4000\n",
            "   macro avg     0.8726    0.8720    0.8719      4000\n",
            "weighted avg     0.8726    0.8720    0.8719      4000\n",
            "\n",
            "\n",
            "Early stopping at epoch 47\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"best_model.pth\")\n"
      ],
      "metadata": {
        "id": "PlXbLIC80eS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "X7c5ebqG0Q7H",
        "outputId": "a677fcbe-971b-4425-cd5f-027cdf88cb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_09d297f5-ad39-4e14-ba2f-aa7d977a4212\", \"best_model.pth\", 8775778)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}